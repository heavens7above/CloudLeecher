# **Production-Level Review: CloudLeecher.ipynb**

## **üö® Critical Issues Found:**

### **1. MAJOR SECURITY VULNERABILITY**
**Problem:** Ngrok auth token is **hardcoded in notebook** and exposed
```python
AUTH_TOKEN = userdata.get("NGROK-AUTHTOKEN")  # This will fail for most users
```

**Solution:**
```python
# Offer multiple authentication options
def get_ngrok_token():
    # Option 1: Colab Secrets (for advanced users)
    try:
        return userdata.get("NGROK_AUTHTOKEN")  # Fixed key name
    except:
        pass
    
    # Option 2: Environment variable
    token = os.environ.get('NGROK_AUTH_TOKEN')
    if token:
        return token
    
    # Option 3: Input prompt (fallback)
    print("‚ö†Ô∏è No Ngrok token found. Using free tier (limited)")
    return None

# Usage
token = get_ngrok_token()
if token:
    ngrok.set_auth_token(token)
else:
    print("‚ö†Ô∏è Using free ngrok - sessions reset every 2 hours")
```

### **2. MEMORY LEAK & RESOURCE MANAGEMENT**
**Problem:** No cleanup of completed downloads, aria2c accumulates metadata
```python
# Add this function
def cleanup_old_downloads():
    """Remove completed downloads from aria2 memory"""
    try:
        stopped = s.aria2.tellStopped(0, 50, ["gid", "status"])
        for task in stopped:
            if task.get("status") == "complete":
                s.aria2.removeDownloadResult(task["gid"])
    except:
        pass

# Call periodically in a background thread
```

### **3. SESSION DISCONNECTION RISK**
**Problem:** Colab disconnects after 90 minutes of inactivity
```python
# Add keep-alive mechanism
import threading
import requests

def keep_session_alive():
    """Prevent Colab timeout"""
    while True:
        time.sleep(300)  # Every 5 minutes
        try:
            # Make a small request to keep session active
            requests.get(f"{public_url}/health", timeout=5)
        except:
            pass

# Start in background
threading.Thread(target=keep_session_alive, daemon=True).start()
```

### **4. TORRENT FILE HANDLING BUG**
**Problem:** Base64 decoding may fail with incorrect padding
```python
# Fix in add_torrent_file() endpoint:
def add_torrent_file():
    try:
        b64_content = data.get('torrent')
        if not b64_content:
            return jsonify({"error": "Torrent file required"}), 400
        
        # Add padding if needed
        missing_padding = len(b64_content) % 4
        if missing_padding:
            b64_content += '=' * (4 - missing_padding)
        
        raw_bytes = base64.b64decode(b64_content)
        binary_torrent = xmlrpc.client.Binary(raw_bytes)
        
        # Also save .torrent file for persistence
        temp_path = os.path.join("/tmp", f"torrent_{int(time.time())}.torrent")
        with open(temp_path, "wb") as f:
            f.write(raw_bytes)
        
        gid = s.aria2.addTorrent(binary_torrent, [], {"dir": DOWNLOAD_DIR})
        return jsonify({"status": "success", "gid": gid})
    except Exception as e:
        return jsonify({"error": str(e)}), 500
```

### **5. NO ERROR RECOVERY MECHANISM**
**Problem:** If aria2c crashes, everything fails

**Solution:** Add health monitoring
```python
def check_aria2_health():
    """Monitor and restart aria2 if needed"""
    import psutil
    
    for proc in psutil.process_iter(['name']):
        if 'aria2c' in proc.info['name']:
            return True
    
    # Restart aria2
    print("‚ö†Ô∏è aria2c not running, restarting...")
    subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    time.sleep(2)
    return False
```

## **üîß Essential Improvements:**

### **1. CONFIGURATION MANAGEMENT**
```python
# Create config.py
%%writefile config.py
import os

class Config:
    # Paths
    DOWNLOAD_DIR = "/content/drive/MyDrive/TorrentDownloads"
    LOG_DIR = "/content/logs"
    TEMP_DIR = "/content/temp"
    
    # Aria2 Settings
    ARIA2_PORT = 6800
    MAX_CONNECTIONS = 8
    SPLIT_SIZE = 8
    MIN_SPLIT_SIZE = "1M"
    MAX_DOWNLOAD_LIMIT = "0"  # 0 = unlimited
    MAX_UPLOAD_LIMIT = "1K"   # Limit upload to preserve bandwidth
    
    # Flask Settings
    FLASK_PORT = 5000
    SECRET_KEY = os.urandom(24).hex()
    
    # Rate Limiting
    MAX_REQUESTS_PER_MINUTE = 60
    
# Ensure directories exist
for dir_path in [Config.DOWNLOAD_DIR, Config.LOG_DIR, Config.TEMP_DIR]:
    os.makedirs(dir_path, exist_ok=True)
```

### **2. ENHANCED ARIA2 CONFIGURATION**
```python
# Replace current aria2 startup with:
cmd = [
    "aria2c",
    "--enable-rpc",
    f"--rpc-listen-port={Config.ARIA2_PORT}",
    "--rpc-listen-all=true",
    "--rpc-allow-origin-all",
    f"--dir={Config.DOWNLOAD_DIR}",
    "--file-allocation=falloc",  # Better for large files
    f"--max-connection-per-server={Config.MAX_CONNECTIONS}",
    f"--split={Config.SPLIT_SIZE}",
    f"--min-split-size={Config.MIN_SPLIT_SIZE}",
    f"--max-download-limit={Config.MAX_DOWNLOAD_LIMIT}",
    f"--max-upload-limit={Config.MAX_UPLOAD_LIMIT}",
    "--seed-time=0",
    "--continue=true",  # Resume broken downloads
    "--check-integrity=true",  # Verify files
    "--auto-file-renaming=true",
    "--allow-overwrite=false",
    f"--log={Config.LOG_DIR}/aria2.log",
    f"--input-file={Config.LOG_DIR}/aria2.session",  # Session save
    "--save-session-interval=60",  # Save session every 60 seconds
    "--daemon=true"
]
```

### **3. LOGGING & MONITORING**
```python
%%writefile logger.py
import logging
import sys
from datetime import datetime

def setup_logger():
    logger = logging.getLogger("CloudLeecher")
    logger.setLevel(logging.INFO)
    
    # File handler
    file_handler = logging.FileHandler("/content/logs/cloudleecher.log")
    file_handler.setLevel(logging.INFO)
    
    # Console handler
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    
    # Formatter
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)
    
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    return logger

log = setup_logger()
```

### **4. RATE LIMITING & VALIDATION**
```python
from functools import wraps
from flask import request
import time

# Rate limiting dictionary
request_times = {}

def rate_limit(max_per_minute=60):
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            ip = request.remote_addr
            current_time = time.time()
            
            if ip in request_times:
                requests = [t for t in request_times[ip] if current_time - t < 60]
                if len(requests) >= max_per_minute:
                    return jsonify({"error": "Rate limit exceeded"}), 429
                requests.append(current_time)
                request_times[ip] = requests[-max_per_minute:]
            else:
                request_times[ip] = [current_time]
            
            return f(*args, **kwargs)
        return decorated_function
    return decorator

# Apply to endpoints
@app.route('/api/download/magnet', methods=['POST'])
@rate_limit(max_per_minute=10)  # 10 magnets per minute
def add_magnet():
    # ... existing code
```

### **5. FILE TYPE VALIDATION & SANITIZATION**
```python
def validate_magnet(magnet):
    """Validate magnet link format"""
    if not magnet.startswith("magnet:?"):
        return False
    if "xt=urn:btih:" not in magnet:
        return False
    return True

def sanitize_filename(filename):
    """Remove dangerous characters from filenames"""
    import re
    # Remove path traversal attempts
    filename = re.sub(r'\.\./|\.\.\\\\', '', filename)
    # Remove dangerous characters
    filename = re.sub(r'[<>:\"/\\\\|?*]', '_', filename)
    # Limit length
    return filename[:255]
```

### **6. SESSION PERSISTENCE**
```python
# Save ngrok URL to Google Drive for recovery
def save_connection_url(url):
    url_file = "/content/drive/MyDrive/cloudleecher_url.txt"
    with open(url_file, "w") as f:
        f.write(url)
    print(f"‚úÖ Connection URL saved to: {url_file}")

# Load previous URL
def load_previous_url():
    try:
        url_file = "/content/drive/MyDrive/cloudleecher_url.txt"
        if os.path.exists(url_file):
            with open(url_file, "r") as f:
                return f.read().strip()
    except:
        pass
    return None
```

### **7. COMPLETE RESTART MECHANISM**
```python
def restart_services():
    """Full restart of all services"""
    import signal
    
    # Kill existing processes
    os.system("pkill -f aria2c")
    os.system("pkill -f app.py")
    ngrok.kill()
    
    # Clear temp files
    os.system("rm -f /tmp/*.torrent")
    
    # Restart everything
    subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    time.sleep(2)
    
    # Restart Flask
    subprocess.Popen([sys.executable, "app.py"], 
                     stdout=open("flask.log", "w"), 
                     stderr=subprocess.STDOUT)
    time.sleep(3)
    
    # Recreate tunnel
    return ngrok.connect(5000).public_url
```

### **8. ENHANCED STATUS ENDPOINT**
```python
@app.route('/api/system/status', methods=['GET'])
def system_status():
    """Comprehensive system monitoring"""
    import psutil
    
    # Disk usage
    total, used, free = shutil.disk_usage(DOWNLOAD_DIR)
    
    # Memory usage
    memory = psutil.virtual_memory()
    
    # CPU usage
    cpu_percent = psutil.cpu_percent(interval=1)
    
    # Network
    net_io = psutil.net_io_counters()
    
    # Active downloads
    active = s.aria2.tellActive(["completedLength", "downloadSpeed", "totalLength"])
    total_speed = sum(d.get("downloadSpeed", 0) for d in active)
    
    return jsonify({
        "disk": {
            "total": total,
            "used": used,
            "free": free,
            "percent_used": (used / total * 100) if total > 0 else 0
        },
        "memory": {
            "total": memory.total,
            "available": memory.available,
            "percent": memory.percent
        },
        "cpu": cpu_percent,
        "network": {
            "bytes_sent": net_io.bytes_sent,
            "bytes_recv": net_io.bytes_recv
        },
        "downloads": {
            "active": len(active),
            "total_speed": total_speed
        },
        "uptime": time.time() - start_time if 'start_time' in globals() else 0
    })
```

## **üìã Implementation Checklist:**

### **Critical Fixes (Do Now):**
1. [ ] Fix ngrok auth token handling
2. [ ] Add session keep-alive
3. [ ] Implement proper error handling
4. [ ] Add aria2 health monitoring
5. [ ] Fix base64 padding in torrent files

### **Production Enhancements:**
6. [ ] Add comprehensive logging
7. [ ] Implement rate limiting
8. [ ] Add input validation
9. [ ] Create configuration management
10. [ ] Add system monitoring endpoint
11. [ ] Implement session persistence
12. [ ] Add restart/recovery mechanism

### **Optional but Recommended:**
13. [ ] Add Telegram/Email notifications
14. [ ] Implement download queue prioritization
15. [ ] Add file type filtering
16. [ ] Create backup/restore functionality
17. [ ] Add bandwidth scheduling
18. [ ] Implement automatic cleanup

## **üéØ Quick Patch for Immediate Use:**

Add this cell **before the ngrok setup**:

```python
# EMERGENCY PATCH - Add this cell
import threading
import time
import requests

class CloudLeecherPatcher:
    def __init__(self):
        self.keep_alive_thread = None
        self.monitor_thread = None
        
    def start(self):
        # Start keep-alive
        self.keep_alive_thread = threading.Thread(target=self._keep_alive, daemon=True)
        self.keep_alive_thread.start()
        
        # Start health monitor
        self.monitor_thread = threading.Thread(target=self._monitor_health, daemon=True)
        self.monitor_thread.start()
        
    def _keep_alive(self):
        while True:
            time.sleep(300)
            print("üîÑ Keep-alive pulse")
            
    def _monitor_health(self):
        while True:
            time.sleep(30)
            try:
                # Check aria2
                result = subprocess.run(["pgrep", "aria2c"], capture_output=True)
                if result.returncode != 0:
                    print("‚ö†Ô∏è aria2c not running, restarting...")
                    subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            except:
                pass

# Start patcher
patcher = CloudLeecherPatcher()
patcher.start()
print("‚úÖ Emergency patches applied")
```

## **‚ö†Ô∏è Final Warning:**
1. **Legal Compliance**: Ensure you only download content you have rights to
2. **Rate Limiting**: Don't hammer the aria2 RPC with requests
3. **Storage Management**: Monitor Google Drive usage
4. **Session Limits**: Colab has 12-hour maximum runtime
5. **Bandwidth**: Google may throttle excessive traffic

Your notebook is 80% production-ready. With these fixes, it will be robust, reliable, and suitable for continuous operation.