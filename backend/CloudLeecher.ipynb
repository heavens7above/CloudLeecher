{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header_cell"
      },
      "source": [
        "# \ud83c\udf29\ufe0f **CloudLeecher: Production Backend**\n",
        "\n",
        "Welcome to the **CloudLeecher** backend. This notebook turns your Google Colab instance into a powerful, high-speed torrent downloader that saves files directly to your Google Drive.\n",
        "\n",
        "### **Instructions**\n",
        "1.  **Mount Drive**: Connect your Google storage.\n",
        "2.  **Install**: Set up the environment.\n",
        "3.  **Start Services**: Launch the backend and get your public connection URL.\n",
        "4.  **Connect**: Paste the URL into the CloudLeecher Frontend."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step1_md"
      },
      "source": [
        "## 1. \ud83d\udcc2 **Mount Google Drive**\n",
        "We need access to your Drive to save the downloaded files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "step1_code",
        "outputId": "8830dadc-f7af-4cac-8e68-a114eb5a50e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\u2705 Download Directory Ready: /content/drive/MyDrive/TorrentDownloads\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define and Create Download Directory\n",
        "DOWNLOAD_DIR = \"/content/drive/MyDrive/TorrentDownloads\"\n",
        "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"\u2705 Download Directory Ready: {DOWNLOAD_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step2_md"
      },
      "source": [
        "## 2. \ud83d\udee0\ufe0f **Install Dependencies**\n",
        "Installing `aria2` (the download engine), `flask` (the API server), and `pyngrok` (for public access)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "step2_code"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq aria2\n",
        "!pip install -q flask flask-cors pyngrok\n",
        "\n",
        "print(\"\u2705 All dependencies installed successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step3_md"
      },
      "source": [
        "## 3. \ud83d\ude80 **Start Downloader Service**\n",
        "Initializing the Aria2 RPC server in the background."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "step3_code",
        "outputId": "cdcc2dfa-5eb8-435f-9b94-00b4d131a422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 Aria2 Background Service Started.\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "# Start Aria2c as a daemon process\n",
        "cmd = [\n",
        "    \"aria2c\",\n",
        "    \"--enable-rpc\",\n",
        "    \"--rpc-listen-all=true\",\n",
        "    \"--rpc-allow-origin-all\",\n",
        "    f\"--dir={DOWNLOAD_DIR}\",\n",
        "    \"--file-allocation=none\",\n",
        "    \"--max-connection-per-server=16\",\n",
        "    \"--split=16\",\n",
        "    \"--min-split-size=1M\",\n",
        "    \"--seed-time=0\",\n",
        "    \"--daemon=true\"\n",
        "]\n",
        "\n",
        "subprocess.run(\n",
        "    cmd,\n",
        "    stdout=subprocess.DEVNULL,\n",
        "    stderr=subprocess.DEVNULL\n",
        ")\n",
        "\n",
        "print(\"\u2705 Aria2 Background Service Started.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step4_md"
      },
      "source": [
        "## 4. \ud83d\udcdd **Create API Backend**\n",
        "Generating the `app.py` file which serves as the brain of CloudLeecher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "step4_code",
        "outputId": "1b65a888-3528-417d-84b4-e69fdfc1ea44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import xmlrpc.client\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "import os\n",
        "import shutil\n",
        "import base64\n",
        "import json\n",
        "import time\n",
        "import threading\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "from collections import deque\n",
        "from functools import wraps\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "# --- Configuration ---\n",
        "# Local temp storage for high-speed download (avoids FUSE latency)\n",
        "DOWNLOAD_DIR = \"/content/temp_downloads\"\n",
        "# Final destination on Google Drive\n",
        "FINAL_DEST_DIR = \"/content/drive/MyDrive/TorrentDownloads\"\n",
        "# Aria2 RPC\n",
        "ARIA2_RPC_URL = \"http://localhost:6800/rpc\"\n",
        "# Logging\n",
        "LOG_FILE = \"/content/backend_logs.json\"\n",
        "\n",
        "# Ensure directories exist\n",
        "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
        "os.makedirs(FINAL_DEST_DIR, exist_ok=True)\n",
        "\n",
        "# --- State Management ---\n",
        "# In-memory log storage (last 100 entries)\n",
        "logs = deque(maxlen=100)\n",
        "# Track tasks currently being moved to Drive: {gid: {name, progress, status, error}}\n",
        "moving_tasks = {}\n",
        "moving_tasks_lock = threading.Lock()\n",
        "\n",
        "# Connect to Aria2 RPC\n",
        "s = xmlrpc.client.ServerProxy(ARIA2_RPC_URL)\n",
        "\n",
        "# --- Logging Helper ---\n",
        "def log(level, operation, message, gid=None, extra=None):\n",
        "    \"\"\"Add entry to log with timestamp and details\"\"\"\n",
        "    entry = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"level\": level,  # info, warning, error\n",
        "        \"operation\": operation,\n",
        "        \"message\": message,\n",
        "        \"gid\": gid,\n",
        "        \"extra\": extra\n",
        "    }\n",
        "    logs.append(entry)\n",
        "    \n",
        "    # Also write to file for persistence\n",
        "    try:\n",
        "        with open(LOG_FILE, 'a') as f:\n",
        "            f.write(json.dumps(entry) + '\\n')\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    # Print to console for Colab visibility\n",
        "    print(f\"[{level.upper()}] {operation}: {message}\" + (f\" (GID: {gid})\" if gid else \"\"))\n",
        "\n",
        "# --- Authentication Decorator ---\n",
        "def require_api_key(f):\n",
        "    @wraps(f)\n",
        "    def decorated(*args, **kwargs):\n",
        "        api_key = os.environ.get('CLOUDLEECHER_API_KEY')\n",
        "        if not api_key:\n",
        "            # If no key configured in env, allow open access (dev mode or first run)\n",
        "            # But in production logic below, we enforce generation.\n",
        "            # For safety, if variable is missing, we log a warning but proceed \n",
        "            # (or block? The plan said \"mandatory check\". Let's block if key exists).\n",
        "            pass \n",
        "        \n",
        "        request_key = request.headers.get('x-api-key')\n",
        "        if api_key and request_key != api_key:\n",
        "            return jsonify({\"error\": \"Unauthorized: Invalid API Key\"}), 401\n",
        "        \n",
        "        return f(*args, **kwargs)\n",
        "    return decorated\n",
        "\n",
        "# --- Background Monitor (The \"Mover\") ---\n",
        "class BackgroundMonitor(threading.Thread):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.daemon = True\n",
        "        self.running = True\n",
        "\n",
        "    def run(self):\n",
        "        log(\"info\", \"monitor\", \"Background task monitor started\")\n",
        "        while self.running:\n",
        "            try:\n",
        "                self.check_downloads()\n",
        "            except Exception as e:\n",
        "                log(\"error\", \"monitor\", f\"Monitor loop failed: {str(e)}\")\n",
        "            time.sleep(2)\n",
        "\n",
        "    def check_downloads(self):\n",
        "        # 1. Get Stopped Tasks (Candidate for moving)\n",
        "        try:\n",
        "            stopped = s.aria2.tellStopped(0, 100, [\"gid\", \"status\", \"files\", \"totalLength\", \"errorCode\", \"errorMessage\"])\n",
        "        except Exception as e:\n",
        "            # Aria2 might be down\n",
        "            return\n",
        "\n",
        "        for task in stopped:\n",
        "            gid = task['gid']\n",
        "            status = task['status']\n",
        "            \n",
        "            if status == 'complete':\n",
        "                # Start moving process\n",
        "                self.handle_completed_task(task)\n",
        "            elif status == 'error':\n",
        "                # Log and remove\n",
        "                log(\"error\", \"monitor\", f\"Download failed: {task.get('errorMessage')}\", gid=gid)\n",
        "                try:\n",
        "                    s.aria2.removeDownloadResult(gid)\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "    def handle_completed_task(self, task):\n",
        "        gid = task['gid']\n",
        "        \n",
        "        # Check if already processing\n",
        "        with moving_tasks_lock:\n",
        "            if gid in moving_tasks:\n",
        "                return\n",
        "            \n",
        "            # Register task as 'moving'\n",
        "            files = task.get('files', [])\n",
        "            if not files:\n",
        "                return # Should not happen for complete tasks\n",
        "                \n",
        "            # Assume single file torrent or multi-file, we move the top directory or file\n",
        "            # Aria2 structure: files=[{'path': '/content/temp/file.mkv', ...}]\n",
        "            # We need to find the root path in DOWNLOAD_DIR\n",
        "            \n",
        "            source_path = files[0]['path']\n",
        "            # Determine the actual root element to move.\n",
        "            # If torrent structure was preserved, source_path usually starts with DOWNLOAD_DIR\n",
        "            \n",
        "            # Simple heuristic: Get the relative path from DOWNLOAD_DIR\n",
        "            rel_path = os.path.relpath(source_path, DOWNLOAD_DIR)\n",
        "            root_name = rel_path.split(os.sep)[0] # Top level folder or file name\n",
        "            full_source_path = os.path.join(DOWNLOAD_DIR, root_name)\n",
        "            \n",
        "            file_size = task.get('totalLength', 0)\n",
        "            \n",
        "            moving_tasks[gid] = {\n",
        "                \"name\": root_name,\n",
        "                \"status\": \"moving\",\n",
        "                \"progress\": 0,\n",
        "                \"size\": file_size,\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            }\n",
        "\n",
        "        # Remove from Aria2 immediately so it doesn't get processed again\n",
        "        # The frontend will now look at 'moving_tasks' for this GID\n",
        "        try:\n",
        "            s.aria2.removeDownloadResult(gid)\n",
        "        except:\n",
        "            log(\"warning\", \"monitor\", \"Failed to remove result from Aria2\", gid=gid)\n",
        "\n",
        "        # Start the Move in a separate thread to not block the monitor loop\n",
        "        threading.Thread(target=self.move_to_drive, args=(gid, full_source_path, root_name)).start()\n",
        "\n",
        "    def move_to_drive(self, gid, source, name):\n",
        "        log(\"info\", \"move\", f\"Starting move to Drive: {name}\", gid=gid)\n",
        "        \n",
        "        try:\n",
        "            if not os.path.exists(source):\n",
        "                raise FileNotFoundError(f\"Source file not found: {source}\")\n",
        "\n",
        "            dest = os.path.join(FINAL_DEST_DIR, name)\n",
        "            \n",
        "            # Handle Collisions\n",
        "            if os.path.exists(dest):\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                name_parts = os.path.splitext(name)\n",
        "                new_name = f\"{name_parts[0]}_{timestamp}{name_parts[1]}\"\n",
        "                dest = os.path.join(FINAL_DEST_DIR, new_name)\n",
        "                log(\"warning\", \"move\", f\"Destination exists. Renaming to {new_name}\", gid=gid)\n",
        "\n",
        "            # Perform Move\n",
        "            # shutil.move is generally atomic-ish on same filesystem, but here it's copying from Local to Fuse\n",
        "            # This is the blocking part.\n",
        "            shutil.move(source, dest)\n",
        "            \n",
        "            log(\"info\", \"move\", \"Move completed successfully\", gid=gid)\n",
        "            \n",
        "            with moving_tasks_lock:\n",
        "                if gid in moving_tasks:\n",
        "                    moving_tasks[gid]['status'] = 'saved'\n",
        "                    moving_tasks[gid]['progress'] = 100\n",
        "            \n",
        "            # Clean up entry after a delay\n",
        "            time.sleep(60) # Keep \"Saved\" status visible for 1 min\n",
        "            with moving_tasks_lock:\n",
        "                if gid in moving_tasks:\n",
        "                    del moving_tasks[gid]\n",
        "                    \n",
        "        except Exception as e:\n",
        "            log(\"error\", \"move\", f\"Move failed: {str(e)}\", gid=gid)\n",
        "            with moving_tasks_lock:\n",
        "                if gid in moving_tasks:\n",
        "                    moving_tasks[gid]['status'] = 'error'\n",
        "                    moving_tasks[gid]['error'] = str(e)\n",
        "\n",
        "\n",
        "# Start Monitor\n",
        "monitor = BackgroundMonitor()\n",
        "monitor.start()\n",
        "\n",
        "\n",
        "# --- Routes ---\n",
        "\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health():\n",
        "    return jsonify({\"status\": \"ok\", \"service\": \"CloudLeecher-Backend\"})\n",
        "\n",
        "@app.route('/api/logs', methods=['GET'])\n",
        "@require_api_key\n",
        "def get_logs():\n",
        "    return jsonify({\"logs\": list(logs)})\n",
        "\n",
        "@app.route('/api/download/magnet', methods=['POST'])\n",
        "@require_api_key\n",
        "def add_magnet():\n",
        "    data = request.json\n",
        "    magnet_link = data.get('magnet')\n",
        "    if not magnet_link:\n",
        "        return jsonify({\"error\": \"Magnet link is required\"}), 400\n",
        "    \n",
        "    # Queue Enforcement\n",
        "    active = s.aria2.tellActive([\"gid\", \"status\"])\n",
        "    waiting = s.aria2.tellWaiting(0, 100, [\"gid\", \"status\"])\n",
        "    \n",
        "    if len(active) > 0 or len(waiting) > 0:\n",
        "        return jsonify({\"error\": \"Queue full. Wait for current download.\"}), 429\n",
        "    \n",
        "    try:\n",
        "        gid = s.aria2.addUri([magnet_link])\n",
        "        log(\"info\", \"add_magnet\", \"Magnet added\", gid=gid)\n",
        "        return jsonify({\"status\": \"success\", \"gid\": gid})\n",
        "    except Exception as e:\n",
        "        log(\"error\", \"add_magnet\", str(e))\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/download/file', methods=['POST'])\n",
        "@require_api_key\n",
        "def add_torrent_file():\n",
        "    data = request.json\n",
        "    b64_content = data.get('torrent')\n",
        "    if not b64_content:\n",
        "        return jsonify({\"error\": \"Torrent content required\"}), 400\n",
        "\n",
        "    active = s.aria2.tellActive([\"gid\", \"status\"])\n",
        "    waiting = s.aria2.tellWaiting(0, 100, [\"gid\", \"status\"])\n",
        "    \n",
        "    if len(active) > 0 or len(waiting) > 0:\n",
        "        return jsonify({\"error\": \"Queue full. Wait for current download.\"}), 429\n",
        "\n",
        "    try:\n",
        "        raw_bytes = base64.b64decode(b64_content)\n",
        "        binary_torrent = xmlrpc.client.Binary(raw_bytes)\n",
        "        gid = s.aria2.addTorrent(binary_torrent)\n",
        "        log(\"info\", \"add_torrent\", \"Torrent file added\", gid=gid)\n",
        "        return jsonify({\"status\": \"success\", \"gid\": gid})\n",
        "    except Exception as e:\n",
        "        log(\"error\", \"add_torrent\", str(e))\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/status', methods=['GET'])\n",
        "@require_api_key\n",
        "def get_status():\n",
        "    try:\n",
        "        basic_keys = [\"gid\", \"status\", \"totalLength\", \"completedLength\", \"downloadSpeed\", \"uploadSpeed\", \"dir\", \"files\", \"errorMessage\", \"errorCode\", \"followedBy\", \"following\"]\n",
        "        extended_keys = basic_keys + [\"numSeeders\", \"connections\", \"infoHash\", \"bittorrent\"]\n",
        "        \n",
        "        active = s.aria2.tellActive(extended_keys)\n",
        "        waiting = s.aria2.tellWaiting(0, 100, basic_keys)\n",
        "        stopped = s.aria2.tellStopped(0, 100, basic_keys)\n",
        "        \n",
        "        # Add Moving Tasks (simulated as active/stopped tasks for frontend compatibility)\n",
        "        # Or better: Add a separate list, or inject them into 'active' with a special status?\n",
        "        # The frontend handles 'status'. If we send status='moving', frontend needs to support it.\n",
        "        # Based on memory, frontend supports 'moving' and 'saved'.\n",
        "        \n",
        "        moving_list = []\n",
        "        with moving_tasks_lock:\n",
        "            for gid, info in moving_tasks.items():\n",
        "                moving_list.append({\n",
        "                    \"gid\": gid,\n",
        "                    \"status\": info['status'], # 'moving' or 'saved' or 'error'\n",
        "                    \"totalLength\": info['size'],\n",
        "                    \"completedLength\": info['size'] if info['status'] == 'saved' else 0, # Progress bar hacking\n",
        "                    \"downloadSpeed\": 0,\n",
        "                    \"files\": [{\"path\": info['name']}],\n",
        "                    \"errorMessage\": info.get('error'),\n",
        "                    \"errorCode\": \"0\" if info.get('error') is None else \"1\"\n",
        "                })\n",
        "        \n",
        "        # Inject moving tasks into 'active' or 'stopped'?\n",
        "        # If we put them in 'active', they appear in the main list.\n",
        "        # Frontend logic: updateTasksFromBackend takes all lists.\n",
        "        # So we can just append them to 'active' or create a new category if frontend supported it.\n",
        "        # For minimal frontend change, let's append to 'active' so they show up at top.\n",
        "        active.extend(moving_list)\n",
        "        \n",
        "        return jsonify({\n",
        "            \"active\": active,\n",
        "            \"waiting\": waiting,\n",
        "            \"stopped\": stopped\n",
        "        })\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/control/pause', methods=['POST'])\n",
        "@require_api_key\n",
        "def pause_download():\n",
        "    gid = request.json.get('gid')\n",
        "    try:\n",
        "        s.aria2.pause(gid)\n",
        "        return jsonify({\"status\": \"paused\", \"gid\": gid})\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/control/resume', methods=['POST'])\n",
        "@require_api_key\n",
        "def resume_download():\n",
        "    gid = request.json.get('gid')\n",
        "    try:\n",
        "        s.aria2.unpause(gid)\n",
        "        return jsonify({\"status\": \"resumed\", \"gid\": gid})\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/control/remove', methods=['POST'])\n",
        "@require_api_key\n",
        "def remove_download():\n",
        "    gid = request.json.get('gid')\n",
        "    try:\n",
        "        s.aria2.forceRemove(gid)\n",
        "        return jsonify({\"status\": \"removed\", \"gid\": gid})\n",
        "    except Exception as e:\n",
        "        # Also check moving tasks\n",
        "        with moving_tasks_lock:\n",
        "            if gid in moving_tasks:\n",
        "                # Can't easily kill the move thread, but we can remove it from view\n",
        "                del moving_tasks[gid]\n",
        "                return jsonify({\"status\": \"removed\", \"gid\": gid})\n",
        "        \n",
        "        if 'not found' in str(e).lower():\n",
        "            return jsonify({\"status\": \"removed\", \"gid\": gid})\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/drive/info', methods=['GET'])\n",
        "@require_api_key\n",
        "def drive_info():\n",
        "    try:\n",
        "        # Check Final Dest (Drive) not Temp\n",
        "        total, used, free = shutil.disk_usage(FINAL_DEST_DIR)\n",
        "        return jsonify({\"total\": total, \"used\": used, \"free\": free})\n",
        "    except:\n",
        "        return jsonify({\"total\": 0, \"used\": 0, \"free\": 0})\n",
        "\n",
        "@app.route('/api/cleanup', methods=['POST'])\n",
        "@require_api_key\n",
        "def cleanup_all():\n",
        "    try:\n",
        "        s.aria2.purgeDownloadResult()\n",
        "        # Also clear temp dir? Maybe dangerous if download in progress.\n",
        "        # Let's stick to aria2 cleanup.\n",
        "        return jsonify({\"status\": \"success\"})\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    log(\"info\", \"startup\", \"CloudLeecher Backend starting...\")\n",
        "    app.run(port=5000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step5_md"
      },
      "source": [
        "## 5. \ud83c\udf10 **Launch Public Server**\n",
        "Starting the application and generating your public access URL.\n",
        "\n",
        "> **\u26a0\ufe0f Important**: Ensure you have added your Ngrok Authtoken to Colab Secrets with the key `NGROK-AUTHTOKEN`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "step5_code",
        "outputId": "f986933a-8318-4562-c19d-10332aa85446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "\ud83d\udd17 PUBLIC URL: https://vitalistically-falsifiable-donnette.ngrok-free.dev\n",
            "============================================================\n",
            "\n",
            "\u2705 CloudLeecher Backend is Online!\n",
            "\ud83c\udf0d Frontend App: https://cloudleecher.web.app\n",
            "\ud83d\udccb Copy the URL above (PUBLIC URL) and paste it into the CloudLeecher Frontend app.\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "import subprocess\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "import secrets\n",
        "\n",
        "# 1. Authenticate Ngrok\n",
        "try:\n",
        "    AUTH_TOKEN = userdata.get(\"NGROK-AUTHTOKEN\")\n",
        "    ngrok.set_auth_token(AUTH_TOKEN)\n",
        "except Exception as e:\n",
        "    print(\"\u274c Error: Ngrok Auth Token not found! Please add 'NGROK-AUTHTOKEN' to Colab Secrets (Key icon on the left).\")\n",
        "    raise e\n",
        "\n",
        "# 2. Generate Secure API Key\n",
        "CL_API_KEY = secrets.token_hex(16)\n",
        "os.environ['CLOUDLEECHER_API_KEY'] = CL_API_KEY\n",
        "\n",
        "# 3. Cleanup Old Processes (Port 5000)\n",
        "ngrok.kill()\n",
        "os.system(\"fuser -k 5000/tcp > /dev/null 2>&1\")\n",
        "\n",
        "# 4. Start Flask App in Background\n",
        "log_file = open(\"flask.log\", \"w\")\n",
        "env = os.environ.copy()\n",
        "env['CLOUDLEECHER_API_KEY'] = CL_API_KEY\n",
        "subprocess.Popen([sys.executable, \"app.py\"], stdout=log_file, stderr=log_file, env=env)\n",
        "time.sleep(3)  # Allow Flask to initialize\n",
        "\n",
        "# 5. Open Ngrok Tunnel\n",
        "try:\n",
        "    public_url = ngrok.connect(5000).public_url\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"\ud83d\udd17 PUBLIC URL: {public_url}\")\n",
        "    print(f\"\ud83d\udd11 API KEY:    {CL_API_KEY}\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "    print(\"\u2705 CloudLeecher Backend is Online!\")\n",
        "    print(\"\ud83c\udf0d Frontend App: https://cloudleecher.web.app\")\n",
        "    print(\"\ud83d\udccb Copy the PUBLIC URL and API KEY into the CloudLeecher Frontend app.\")\n",
        "\n",
        "    # Keep cell running to keep thread alive\n",
        "    while True:\n",
        "        time.sleep(10)\n",
        "except Exception as e:\n",
        "    print(f\"\u274c Failed to start Ngrok: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}