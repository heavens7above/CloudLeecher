{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header_cell"
      },
      "source": [
        "# üå©Ô∏è **CloudLeecher: Production Backend**\n",
        "\n",
        "Welcome to the **CloudLeecher** backend. This notebook turns your Google Colab instance into a powerful, high-speed torrent downloader that saves files directly to your Google Drive.\n",
        "\n",
        "### **Instructions**\n",
        "1.  **Mount Drive**: Connect your Google storage.\n",
        "2.  **Install**: Clone repo and set up the environment.\n",
        "3.  **Start Services**: Launch the backend services.\n",
        "4.  **Connect**: Paste the URL and API Key into the CloudLeecher Frontend."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step1_md"
      },
      "source": [
        "## 1. üìÇ **Mount Google Drive**\n",
        "We need access to your Drive to save the downloaded files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "step1_code"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define and Create Download Directory\n",
        "TEMP_DIR = \"/content/temp_downloads\"\n",
        "FINAL_DIR = \"/content/drive/MyDrive/TorrentDownloads\"\n",
        "os.makedirs(TEMP_DIR, exist_ok=True)\n",
        "os.makedirs(FINAL_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"‚úÖ Temp Directory Ready: {TEMP_DIR}\")\n",
        "print(f\"‚úÖ Final Directory Ready: {FINAL_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step2_md"
      },
      "source": [
        "## 2. üõ†Ô∏è **Install Dependencies**\n",
        "Cloning the CloudLeecher repository and installing dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "step2_code"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq aria2\n",
        "\n",
        "import os\n",
        "# Clone or Pull Repo\n",
        "if not os.path.exists('/content/CloudLeecher'):\n",
        "    !git clone https://github.com/heavens7above/CloudLeecher.git\n",
        "else:\n",
        "    !cd CloudLeecher && git pull\n",
        "\n",
        "!pip install -r CloudLeecher/backend/requirements.txt\n",
        "\n",
        "print(\"‚úÖ All dependencies installed successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step3_md"
      },
      "source": [
        "## 3. üöÄ **Start Downloader Service**\n",
        "Initializing the Aria2 RPC server in the background (using local temp storage for reliability)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "step3_code"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Use local temp dir for reliability (FUSE workaround)\n",
        "TEMP_DIR = \"/content/temp_downloads\"\n",
        "os.makedirs(TEMP_DIR, exist_ok=True)\n",
        "\n",
        "# Start Aria2c as a daemon process\n",
        "# We use the local temp dir for speed and stability\n",
        "cmd = [\n",
        "    \"aria2c\",\n",
        "    \"--enable-rpc\",\n",
        "    \"--rpc-listen-all=true\",\n",
        "    \"--rpc-allow-origin-all\",\n",
        "    f\"--dir={TEMP_DOWNLOAD_DIR}\",\n",
        "    f\"--dir={TEMP_DIR}\",\n",
        "    \"--file-allocation=none\",\n",
        "    \"--max-connection-per-server=16\",\n",
        "    \"--split=16\",\n",
        "    \"--min-split-size=1M\",\n",
        "    \"--seed-time=0\",\n",
        "    \"--daemon=true\"\n",
        "]\n",
        "\n",
        "subprocess.run(\n",
        "    cmd,\n",
        "    stdout=subprocess.DEVNULL,\n",
        "    stderr=subprocess.DEVNULL\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Aria2 Background Service Started (Staging: /content/temp_downloads).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step4_md"
      },
      "source": [
        "## 4. üìù **Create API Backend**\n",
        "Generating the `app.py` file which serves as the brain of CloudLeecher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "step4_code",
        "outputId": "1b65a888-3528-417d-84b4-e69fdfc1ea44"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import xmlrpc.client\n",
        "from flask import Flask, request, jsonify, abort\n",
        "from flask_cors import CORS\n",
        "import os\n",
        "import shutil\n",
        "import base64\n",
        "import json\n",
        "import time\n",
        "import threading\n",
        "import secrets\n",
        "from datetime import datetime\n",
        "from collections import deque\n",
        "import threading\n",
        "import time\n",
        "import secrets\n",
        "from functools import wraps\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "# Configuration\n",
        "# Use a local temporary directory for downloading to avoid FUSE issues\n",
        "TEMP_DOWNLOAD_DIR = \"/content/temp_downloads\"\n",
        "# Final destination on Google Drive\n",
        "FINAL_DIR = \"/content/drive/MyDrive/TorrentDownloads\"\n",
        "\n",
        "ARIA2_RPC_URL = \"http://localhost:6800/rpc\"\n",
        "LOG_FILE = \"/content/backend_logs.json\"\n",
        "\n",
        "# Ensure directories exist\n",
        "os.makedirs(TEMP_DOWNLOAD_DIR, exist_ok=True)\n",
        "os.makedirs(FINAL_DIR, exist_ok=True)\n",
        "\n",
        "# Authentication\n",
        "API_KEY = os.environ.get('CLOUDLEECHER_API_KEY')\n",
        "if not API_KEY:\n",
        "    # If not provided via env, generate one (fallback)\n",
        "    API_KEY = secrets.token_hex(16)\n",
        "    print(f\"\\n{'='*50}\\nGenerated API Key: {API_KEY}\\n{'='*50}\\n\")\n",
        "else:\n",
        "    print(f\"\\n{'='*50}\\nUsing Configured API Key: {API_KEY}\\n{'='*50}\\n\")\n",
        "\n",
        "# --- Configuration ---\n",
        "# Use a local path for high-speed download (SSD), then move to Drive\n",
        "TEMP_DOWNLOAD_DIR = \"/content/temp_downloads\"\n",
        "FINAL_DRIVE_DIR = \"/content/drive/MyDrive/TorrentDownloads\"\n",
        "ARIA2_RPC_URL = \"http://localhost:6800/rpc\"\n",
        "LOG_FILE = \"/content/backend_logs.json\"\n",
        "\n",
        "# API Security\n",
        "API_KEY = os.environ.get(\"CL_API_KEY\") or secrets.token_urlsafe(12)\n",
        "\n",
        "# Ensure directories exist\n",
        "os.makedirs(TEMP_DOWNLOAD_DIR, exist_ok=True)\n",
        "os.makedirs(FINAL_DRIVE_DIR, exist_ok=True)\n",
        "\n",
        "# --- State Management ---\n",
        "# In-memory log storage (last 100 entries)\n",
        "logs = deque(maxlen=100)\n",
        "\n",
        "# Track tasks that are currently being moved to Drive\n",
        "# Format: gid -> { name: str, size: int, start_time: float }\n",
        "uploading_tasks = {}\n",
        "uploading_lock = threading.Lock()\n",
        "\n",
        "# Connect to Aria2 RPC\n",
        "s = xmlrpc.client.ServerProxy(ARIA2_RPC_URL)\n",
        "\n",
        "def log(level, operation, message, gid=None, extra=None):\n",
        "    \"\"\"Add entry to log with timestamp and details\"\"\"\n",
        "    entry = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"level\": level,  # info, warning, error\n",
        "        \"operation\": operation,\n",
        "        \"message\": message,\n",
        "        \"gid\": gid,\n",
        "        \"extra\": extra\n",
        "    }\n",
        "    logs.append(entry)\n",
        "    \n",
        "    # Also write to file for persistence\n",
        "    try:\n",
        "        with open(LOG_FILE, 'a') as f:\n",
        "            f.write(json.dumps(entry) + '\\n')\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    # Print to console\n",
        "    print(f\"[{level.upper()}] {operation}: {message}\" + (f\" (GID: {gid})\" if gid else \"\"))\n",
        "\n",
        "def check_auth(f):\n",
        "    @wraps(f)\n",
        "    def decorated_function(*args, **kwargs):\n",
        "        if request.method == 'OPTIONS':\n",
        "            return f(*args, **kwargs)\n",
        "            \n",
        "        request_key = request.headers.get('x-api-key')\n",
        "        if not request_key or request_key != API_KEY:\n",
        "            log(\"warning\", \"auth\", \"Unauthorized access attempt\")\n",
        "            return jsonify({\"error\": \"Unauthorized: Invalid or missing API Key\"}), 401\n",
        "        return f(*args, **kwargs)\n",
        "    return decorated_function\n",
        "\n",
        "class BackgroundMonitor(threading.Thread):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.daemon = True\n",
        "        self.stopped = False\n",
        "\n",
        "    def run(self):\n",
        "        log(\"info\", \"monitor\", \"Background monitor started\")\n",
        "        while not self.stopped:\n",
        "            try:\n",
        "                self.check_completed_downloads()\n",
        "            except Exception as e:\n",
        "                pass # Silent fail (e.g. aria2 not ready yet)\n",
        "            time.sleep(5)\n",
        "\n",
        "    def check_completed_downloads(self):\n",
        "        try:\n",
        "            # Get stopped tasks (includes complete, error, removed)\n",
        "            stopped = s.aria2.tellStopped(0, 100, [\"gid\", \"status\", \"files\", \"bittorrent\", \"totalLength\", \"errorCode\"])\n",
        "            \n",
        "            for task in stopped:\n",
        "                status = task['status']\n",
        "                gid = task['gid']\n",
        "                \n",
        "                if status == 'complete':\n",
        "                    self.handle_complete_task(task)\n",
        "                elif status == 'error':\n",
        "                     # Log error and remove\n",
        "                     err_code = task.get('errorCode', 'unknown')\n",
        "                     log(\"error\", \"download\", f\"Task failed with error code {err_code}\", gid=gid)\n",
        "                     try: s.aria2.removeDownloadResult(gid)\n",
        "                     except: pass\n",
        "                elif status == 'removed':\n",
        "                     try: s.aria2.removeDownloadResult(gid)\n",
        "                     except: pass\n",
        "                     \n",
        "        except Exception as e:\n",
        "            pass\n",
        "\n",
        "    def handle_complete_task(self, task):\n",
        "        gid = task['gid']\n",
        "        files = task.get('files', [])\n",
        "        \n",
        "        if not files:\n",
        "            try: s.aria2.removeDownloadResult(gid)\n",
        "            except: pass\n",
        "            return\n",
        "\n",
        "        # Try to find the root file or directory\n",
        "        bt_name = task.get('bittorrent', {}).get('info', {}).get('name')\n",
        "        \n",
        "        source_path = None\n",
        "        \n",
        "        # Strategy 1: Look for the name provided in metadata\n",
        "        if bt_name:\n",
        "             possible_path = os.path.join(TEMP_DOWNLOAD_DIR, bt_name)\n",
        "             if os.path.exists(possible_path):\n",
        "                 source_path = possible_path\n",
        "        \n",
        "        # Strategy 2: Use the first file path\n",
        "        if not source_path and files:\n",
        "            first_file_path = files[0]['path']\n",
        "            # If the path starts with TEMP_DOWNLOAD_DIR, great\n",
        "            if os.path.exists(first_file_path):\n",
        "                # If it's a multi-file torrent, first_file_path is deep inside\n",
        "                # We want the top-level directory.\n",
        "                rel_path = os.path.relpath(first_file_path, TEMP_DOWNLOAD_DIR)\n",
        "                top_level = rel_path.split(os.sep)[0]\n",
        "                possible_path = os.path.join(TEMP_DOWNLOAD_DIR, top_level)\n",
        "                if os.path.exists(possible_path):\n",
        "                    source_path = possible_path\n",
        "\n",
        "        if not source_path:\n",
        "             log(\"error\", \"move\", \"Could not locate downloaded files\", gid=gid)\n",
        "             # Don't remove result so we can debug? Or remove to avoid loop?\n",
        "             # Remove it to avoid infinite loop\n",
        "             try: s.aria2.removeDownloadResult(gid)\n",
        "             except: pass\n",
        "             return\n",
        "\n",
        "        dest_path = os.path.join(FINAL_DIR, os.path.basename(source_path))\n",
        "        \n",
        "        # Handle collision\n",
        "        if os.path.exists(dest_path):\n",
        "            base, ext = os.path.splitext(os.path.basename(source_path))\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            dest_path = os.path.join(FINAL_DIR, f\"{base}_{timestamp}{ext}\")\n",
        "\n",
        "        log(\"info\", \"move\", f\"Moving {os.path.basename(source_path)} to Drive...\", gid=gid)\n",
        "        \n",
        "        try:\n",
        "            shutil.move(source_path, dest_path)\n",
        "            log(\"info\", \"move\", f\"Move successful: {os.path.basename(dest_path)}\", gid=gid)\n",
        "            try: s.aria2.removeDownloadResult(gid)\n",
        "            except: pass\n",
        "        except Exception as e:\n",
        "            log(\"error\", \"move\", f\"Move failed: {str(e)}\", gid=gid)\n",
        "            # If move failed (e.g. Drive full), we leave the task in 'stopped' state\n",
        "            # but 'tellStopped' returns it again.\n",
        "            # To avoid retry loop spam, we might need to blacklist it in memory\n",
        "            # or just log error. \n",
        "            # For now, we leave it.\n",
        "\n",
        "    # Print to console for Colab visibility\n",
        "    print(f\"[{level.upper()}] {operation}: {message}\" + (f\" (GID: {gid})\" if gid else \"\"))\n",
        "\n",
        "# --- Authentication Middleware ---\n",
        "@app.before_request\n",
        "def check_auth():\n",
        "    if request.method == 'OPTIONS':\n",
        "        return\n",
        "\n",
        "    # Allow health check without auth for initial connectivity test\n",
        "    if request.endpoint == 'health':\n",
        "        return\n",
        "\n",
        "    # Check Header\n",
        "    key = request.headers.get('x-api-key')\n",
        "    if key != API_KEY:\n",
        "        return jsonify({\"error\": \"Unauthorized\"}), 401\n",
        "\n",
        "# --- Background Monitor ---\n",
        "class DownloadMonitor(threading.Thread):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.daemon = True\n",
        "        self.running = True\n",
        "\n",
        "    def run(self):\n",
        "        log(\"info\", \"monitor\", \"Background monitor started\")\n",
        "        while self.running:\n",
        "            try:\n",
        "                self.check_downloads()\n",
        "            except Exception as e:\n",
        "                log(\"error\", \"monitor\", f\"Monitor loop failed: {e}\")\n",
        "            time.sleep(2)\n",
        "\n",
        "    def check_downloads(self):\n",
        "        # 1. Get completed tasks from Aria2\n",
        "        try:\n",
        "            stopped = s.aria2.tellStopped(0, 100, [\"gid\", \"status\", \"files\", \"totalLength\"])\n",
        "        except Exception:\n",
        "            return\n",
        "\n",
        "        for task in stopped:\n",
        "            gid = task['gid']\n",
        "            status = task['status']\n",
        "\n",
        "            if status == 'complete':\n",
        "                # Check if already processing\n",
        "                with uploading_lock:\n",
        "                    if gid in uploading_tasks:\n",
        "                        continue\n",
        "\n",
        "                    # Mark as uploading\n",
        "                    files = task.get('files', [])\n",
        "                    if not files:\n",
        "                        continue\n",
        "\n",
        "                    # Determine source path (usually the first file's directory or file itself)\n",
        "                    source_path = files[0]['path']\n",
        "                    \n",
        "                    # Robust path finding:\n",
        "                    rel_path = os.path.relpath(source_path, TEMP_DOWNLOAD_DIR)\n",
        "                    root_name = rel_path.split(os.sep)[0]\n",
        "                    full_source_path = os.path.join(TEMP_DOWNLOAD_DIR, root_name)\n",
        "\n",
        "                    uploading_tasks[gid] = {\n",
        "                        \"name\": root_name,\n",
        "                        \"size\": task['totalLength'],\n",
        "                        \"start_time\": time.time()\n",
        "                    }\n",
        "\n",
        "                self.move_to_drive(gid, full_source_path, root_name)\n",
        "\n",
        "    def move_to_drive(self, gid, source, name):\n",
        "        log(\"info\", \"move\", f\"Starting move to Drive: {name}\", gid=gid)\n",
        "        dest = os.path.join(FINAL_DRIVE_DIR, name)\n",
        "\n",
        "        try:\n",
        "            # Check if destination exists\n",
        "            if os.path.exists(dest):\n",
        "                log(\"warning\", \"move\", f\"Destination exists, renaming: {name}\", gid=gid)\n",
        "                base, ext = os.path.splitext(name)\n",
        "                timestamp = int(time.time())\n",
        "                dest = os.path.join(FINAL_DRIVE_DIR, f\"{base}_{timestamp}{ext}\")\n",
        "\n",
        "            # Perform Move\n",
        "            shutil.move(source, dest)\n",
        "            log(\"info\", \"move\", \"Move completed successfully\", gid=gid)\n",
        "\n",
        "            # Clean up from Aria2\n",
        "            try:\n",
        "                s.aria2.removeDownloadResult(gid)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        except Exception as e:\n",
        "            log(\"error\", \"move\", f\"Failed to move file: {e}\", gid=gid)\n",
        "        finally:\n",
        "            with uploading_lock:\n",
        "                if gid in uploading_tasks:\n",
        "                    del uploading_tasks[gid]\n",
        "\n",
        "# Start Monitor\n",
        "monitor = DownloadMonitor()\n",
        "monitor.start()\n",
        "\n",
        "# --- Routes ---\n",
        "\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health():\n",
        "    return jsonify({\n",
        "        \"status\": \"ok\",\n",
        "        \"service\": \"CloudLeecher-Backend\",\n",
        "        \"auth_required\": True\n",
        "    })\n",
        "\n",
        "@app.route('/api/logs', methods=['GET'])\n",
        "@check_auth\n",
        "def get_logs():\n",
        "    try:\n",
        "        return jsonify({\"logs\": list(logs)})\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "    return jsonify({\"logs\": list(logs)})\n",
        "\n",
        "@app.route('/api/download/magnet', methods=['POST'])\n",
        "@check_auth\n",
        "def add_magnet():\n",
        "    data = request.json\n",
        "    magnet_link = data.get('magnet')\n",
        "    if not magnet_link:\n",
        "        return jsonify({\"error\": \"Magnet link is required\"}), 400\n",
        "    \n",
        "    active = s.aria2.tellActive([\"gid\", \"status\"])\n",
        "    waiting = s.aria2.tellWaiting(0, 100, [\"gid\", \"status\"])\n",
        "    \n",
        "    if len(active) > 0 or len(waiting) > 0:\n",
        "        log(\"warning\", \"add_magnet\", f\"Rejected: {len(active)} active, {len(waiting)} waiting tasks already exist\")\n",
        "        return jsonify({\"error\": \"Another download is already in progress. Please wait for it to complete.\"}), 429\n",
        "    \n",
        "\n",
        "    try:\n",
        "        active = s.aria2.tellActive([\"gid\", \"status\"])\n",
        "        waiting = s.aria2.tellWaiting(0, 100, [\"gid\", \"status\"])\n",
        "        \n",
        "        if len(active) > 0 or len(waiting) > 0:\n",
        "            log(\"warning\", \"add_magnet\", f\"Rejected: {len(active)} active, {len(waiting)} waiting tasks already exist\")\n",
        "            return jsonify({\"error\": \"Another download is already in progress. Please wait for it to complete.\"}), 429\n",
        "    except Exception as e:\n",
        "         log(\"error\", \"add_magnet\", f\"Aria2 connection failed: {str(e)}\")\n",
        "         return jsonify({\"error\": \"Backend not connected to Aria2\"}), 500\n",
        "    \n",
        "    try:\n",
        "        # Note: DOWNLOAD_DIR is set in aria2c startup args, but addUri inherits it.\n",
        "        # We don't need to specify dir here unless we want to override.\n",
        "        gid = s.aria2.addUri([magnet_link])\n",
        "        log(\"info\", \"add_magnet\", \"Magnet link added\", gid=gid)\n",
        "        return jsonify({\"status\": \"success\", \"gid\": gid})\n",
        "    except Exception as e:\n",
        "        log(\"error\", \"add_magnet\", str(e))\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/download/file', methods=['POST'])\n",
        "@check_auth\n",
        "def add_torrent_file():\n",
        "    try:\n",
        "        data = request.json\n",
        "        b64_content = data.get('torrent')\n",
        "        if not b64_content:\n",
        "            log(\"error\", \"add_torrent_file\", \"Torrent file content is required\")\n",
        "            return jsonify({\"error\": \"Torrent file content is required\"}), 400\n",
        "\n",
        "        active = s.aria2.tellActive([\"gid\", \"status\"])\n",
        "        waiting = s.aria2.tellWaiting(0, 100, [\"gid\", \"status\"])\n",
        "        \n",
        "        if len(active) > 0 or len(waiting) > 0:\n",
        "            log(\"warning\", \"add_torrent_file\", f\"Rejected: {len(active)} active, {len(waiting)} waiting tasks already exist\")\n",
        "            return jsonify({\"error\": \"Another download is already in progress. Please wait for it to complete.\"}), 429\n",
        "    data = request.json\n",
        "    b64_content = data.get('torrent')\n",
        "    if not b64_content:\n",
        "        return jsonify({\"error\": \"Torrent content required\"}), 400\n",
        "\n",
        "    try:\n",
        "        raw_bytes = base64.b64decode(b64_content)\n",
        "        binary_torrent = xmlrpc.client.Binary(raw_bytes)\n",
        "        \n",
        "        log(\"info\", \"add_torrent_file\", f\"Received torrent file ({len(raw_bytes)} bytes), adding to aria2...\")\n",
        "        gid = s.aria2.addTorrent(binary_torrent)\n",
        "        log(\"info\", \"add_torrent_file\", \"Torrent file added successfully, downloading metadata...\", gid=gid)\n",
        "        \n",
        "        try:\n",
        "            status = s.aria2.tellStatus(gid, [\"gid\", \"status\", \"files\", \"bittorrent\"])\n",
        "            torrent_name = status.get('bittorrent', {}).get('info', {}).get('name', 'Unknown')\n",
        "            log(\"info\", \"add_torrent_file\", f\"Torrent name: {torrent_name}\", gid=gid, extra={\"status\": status.get('status')})\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        gid = s.aria2.addTorrent(binary_torrent)\n",
        "        log(\"info\", \"add_torrent_file\", \"Torrent file added\", gid=gid)\n",
        "        return jsonify({\"status\": \"success\", \"gid\": gid})\n",
        "    except Exception as e:\n",
        "        log(\"error\", \"add_torrent_file\", str(e))\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/status', methods=['GET'])\n",
        "@check_auth\n",
        "def get_status():\n",
        "    try:\n",
        "        basic_keys = [\"gid\", \"status\", \"totalLength\", \"completedLength\", \"downloadSpeed\", \"uploadSpeed\", \"dir\", \"files\", \"errorMessage\", \"errorCode\", \"followedBy\", \"following\"]\n",
        "        extended_keys = basic_keys + [\"numSeeders\", \"connections\", \"infoHash\", \"bittorrent\"]\n",
        "        \n",
        "        active = s.aria2.tellActive(extended_keys)\n",
        "        waiting = s.aria2.tellWaiting(0, 100, basic_keys)\n",
        "        stopped = s.aria2.tellStopped(0, 100, basic_keys)\n",
        "        \n",
        "        # Standard Aria2 Status\n",
        "        keys = [\"gid\", \"status\", \"totalLength\", \"completedLength\", \"downloadSpeed\", \"uploadSpeed\", \"dir\", \"files\", \"errorMessage\", \"errorCode\", \"numSeeders\", \"connections\", \"infoHash\", \"bittorrent\", \"followedBy\", \"following\"]\n",
        "\n",
        "        active = s.aria2.tellActive(keys)\n",
        "        waiting = s.aria2.tellWaiting(0, 100, keys)\n",
        "        stopped = s.aria2.tellStopped(0, 100, keys)\n",
        "\n",
        "        # Inject Uploading Tasks\n",
        "        with uploading_lock:\n",
        "            for gid, info in uploading_tasks.items():\n",
        "                # Fake an aria2 task object\n",
        "                upload_task = {\n",
        "                    \"gid\": gid,\n",
        "                    \"status\": \"uploading\", # Custom status\n",
        "                    \"totalLength\": str(info['size']),\n",
        "                    \"completedLength\": str(info['size']),\n",
        "                    \"downloadSpeed\": \"0\",\n",
        "                    \"uploadSpeed\": \"0\",\n",
        "                    \"files\": [{\"path\": info['name']}],\n",
        "                    \"dir\": FINAL_DRIVE_DIR\n",
        "                }\n",
        "                # Filter out the stopped task from aria2 if it's still there\n",
        "                stopped = [t for t in stopped if t['gid'] != gid]\n",
        "                active.append(upload_task)\n",
        "\n",
        "        return jsonify({\n",
        "            \"active\": active,\n",
        "            \"waiting\": waiting,\n",
        "            \"stopped\": stopped\n",
        "        })\n",
        "    except Exception as e:\n",
        "        log(\"error\", \"get_status\", str(e))\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/control/pause', methods=['POST'])\n",
        "@check_auth\n",
        "def pause_download():\n",
        "    gid = request.json.get('gid')\n",
        "    try:\n",
        "        s.aria2.pause(gid)\n",
        "        return jsonify({\"status\": \"paused\", \"gid\": gid})\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/control/resume', methods=['POST'])\n",
        "@check_auth\n",
        "def resume_download():\n",
        "    gid = request.json.get('gid')\n",
        "    try:\n",
        "        s.aria2.unpause(gid)\n",
        "        return jsonify({\"status\": \"resumed\", \"gid\": gid})\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/control/remove', methods=['POST'])\n",
        "@check_auth\n",
        "def remove_download():\n",
        "    gid = request.json.get('gid')\n",
        "    try:\n",
        "        s.aria2.forceRemove(gid)\n",
        "        return jsonify({\"status\": \"removed\", \"gid\": gid})\n",
        "    except xmlrpc.client.Fault as e:\n",
        "        if 'not found' in str(e).lower():\n",
        "            log(\"info\", \"remove_download\", \"GID not found (already removed)\", gid=request.json.get('gid'))\n",
        "            return jsonify({\"status\": \"removed\", \"gid\": request.json.get('gid')})\n",
        "        else:\n",
        "            log(\"error\", \"remove_download\", f\"Aria2 error: {str(e)}\", gid=request.json.get('gid'))\n",
        "            return jsonify({\"error\": str(e)}), 500\n",
        "    except Exception as e:\n",
        "        return jsonify({\"status\": \"removed\", \"gid\": gid})\n",
        "\n",
        "@app.route('/api/drive/info', methods=['GET'])\n",
        "@check_auth\n",
        "def drive_info():\n",
        "    try:\n",
        "        total, used, free = shutil.disk_usage(FINAL_DIR)\n",
        "        # Check Final Drive Destination\n",
        "        total, used, free = shutil.disk_usage(FINAL_DRIVE_DIR)\n",
        "        return jsonify({\n",
        "            \"total\": total,\n",
        "            \"used\": used,\n",
        "            \"free\": free\n",
        "        })\n",
        "    except Exception:\n",
        "        return jsonify({\"total\": 0, \"used\": 0, \"free\": 0})\n",
        "\n",
        "@app.route('/api/cleanup', methods=['POST'])\n",
        "@check_auth\n",
        "def cleanup_all():\n",
        "    try:\n",
        "        active = s.aria2.tellActive([\"gid\"])\n",
        "        waiting = s.aria2.tellWaiting(0, 9999, [\"gid\"])\n",
        "        stopped = s.aria2.tellStopped(0, 9999, [\"gid\"])\n",
        "        \n",
        "        removed_count = 0\n",
        "        \n",
        "        for task in active + waiting:\n",
        "            try:\n",
        "                s.aria2.forceRemove(task['gid'])\n",
        "                removed_count += 1\n",
        "            except:\n",
        "                pass\n",
        "        \n",
        "        try:\n",
        "            s.aria2.purgeDownloadResult()\n",
        "            removed_count += len(stopped)\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        log(\"info\", \"cleanup_all\", f\"Cleaned up {removed_count} tasks\")\n",
        "        return jsonify({\"status\": \"success\", \"removed\": removed_count})\n",
        "        s.aria2.purgeDownloadResult()\n",
        "        return jsonify({\"status\": \"success\"})\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    log(\"info\", \"startup\", \"CloudLeecher Backend starting...\")\n",
        "    \n",
        "    # Start background monitor\n",
        "    monitor = BackgroundMonitor()\n",
        "    monitor.start()\n",
        "    \n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"üîë API KEY: {API_KEY}\")\n",
        "    print(f\"{'='*50}\\n\")\n",
        "    log(\"info\", \"startup\", f\"Backend starting with API Key protection\")\n",
        "    app.run(port=5000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step5_md"
      },
      "source": [
        "## 4. üåê **Launch Secure Backend**\n",
        "Starting the application securely with an auto-generated API Key.\n",
        "\n",
        "> **‚ö†Ô∏è Important**: Ensure you have added your Ngrok Authtoken to Colab Secrets with the key `NGROK-AUTHTOKEN`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "step5_code"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "import subprocess\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "import secrets\n",
        "import uuid\n",
        "\n",
        "# 1. Generate Security Key\n",
        "api_key = str(uuid.uuid4())\n",
        "os.environ['CLOUDLEECHER_API_KEY'] = api_key\n",
        "os.environ['TEMP_DOWNLOAD_DIR'] = \"/content/temp_downloads\"\n",
        "# DRIVE_MOUNT_PATH defaults to /content/drive in app.py\n",
        "\n",
        "# 2. Authenticate Ngrok\n",
        "try:\n",
        "    AUTH_TOKEN = userdata.get(\"NGROK-AUTHTOKEN\")\n",
        "    ngrok.set_auth_token(AUTH_TOKEN)\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Error: Ngrok Auth Token not found! Please add 'NGROK-AUTHTOKEN' to Colab Secrets.\")\n",
        "    raise e\n",
        "\n",
        "# 3. Cleanup Old Processes\n",
        "ngrok.kill()\n",
        "os.system(\"fuser -k 5000/tcp > /dev/null 2>&1\")\n",
        "\n",
        "# 3. Generate API Key\n",
        "api_key = secrets.token_hex(16)\n",
        "os.environ['CLOUDLEECHER_API_KEY'] = api_key\n",
        "\n",
        "# 4. Start Flask App in Background\n",
        "log_file = open(\"flask.log\", \"w\")\n",
        "env = os.environ.copy()\n",
        "subprocess.Popen([sys.executable, \"app.py\"], stdout=log_file, stderr=log_file, env=env)\n",
        "# 4. Start Flask App in Background\n",
        "log_file = open(\"/content/flask.log\", \"w\")\n",
        "subprocess.Popen(\n",
        "    [sys.executable, \"/content/CloudLeecher/backend/app.py\"], \n",
        "    stdout=log_file, \n",
        "    stderr=log_file,\n",
        "    env=os.environ.copy()\n",
        ")\n",
        "time.sleep(3)  # Allow Flask to initialize\n",
        "\n",
        "# 5. Open Ngrok Tunnel\n",
        "try:\n",
        "    public_url = ngrok.connect(5000).public_url\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"üîó PUBLIC URL: {public_url}\")\n",
        "    print(f\"üîë API KEY:    {api_key}\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "    print(\"‚úÖ CloudLeecher Backend is Online!\")\n",
        "    print(\"üåç Frontend App: https://cloudleecher.web.app\")\n",
        "    print(\"üìã Copy the URL and API KEY above and paste them into the CloudLeecher Frontend app.\")\n",
        "    print(\"üîë The API KEY is printed in the 'Create API Backend' cell output (or previous cell).\")\n",
        "    print(\"üìã Copy the URL and API Key into the CloudLeecher Frontend app.\")\n",
        "\n",
        "    # Keep cell running to keep thread alive\n",
        "    while True:\n",
        "        time.sleep(10)\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to start Ngrok: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}