{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header_cell"
      },
      "source": [
        "# \ud83c\udf29\ufe0f **CloudLeecher: Production Backend**\n",
        "\n",
        "Welcome to the **CloudLeecher** backend. This notebook turns your Google Colab instance into a powerful, high-speed torrent downloader that saves files directly to your Google Drive.\n",
        "\n",
        "### **Instructions**\n",
        "1.  **Mount Drive**: Connect your Google storage.\n",
        "2.  **Install**: Set up the environment.\n",
        "3.  **Start Services**: Launch the backend and get your public connection URL.\n",
        "4.  **Connect**: Paste the URL into the CloudLeecher Frontend."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step1_md"
      },
      "source": [
        "## 1. \ud83d\udcc2 **Mount Google Drive**\n",
        "We need access to your Drive to save the downloaded files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "step1_code",
        "outputId": "8830dadc-f7af-4cac-8e68-a114eb5a50e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\u2705 Download Directory Ready: /content/drive/MyDrive/TorrentDownloads\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define and Create Download Directory\n",
        "DOWNLOAD_DIR = \"/content/drive/MyDrive/TorrentDownloads\"\n",
        "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"\u2705 Download Directory Ready: {DOWNLOAD_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step2_md"
      },
      "source": [
        "## 2. \ud83d\udee0\ufe0f **Install Dependencies**\n",
        "Installing `aria2` (the download engine), `flask` (the API server), and `pyngrok` (for public access)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "step2_code"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq aria2\n",
        "!pip install -q flask flask-cors pyngrok\n",
        "\n",
        "print(\"\u2705 All dependencies installed successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step3_md"
      },
      "source": [
        "## 3. \ud83d\ude80 **Start Downloader Service**\n",
        "Initializing the Aria2 RPC server in the background."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "step3_code",
        "outputId": "cdcc2dfa-5eb8-435f-9b94-00b4d131a422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 Aria2 Background Service Started.\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Define Temp Directory for Initial Downloads\n",
        "TEMP_DIR = \"/content/temp_downloads\"\n",
        "os.makedirs(TEMP_DIR, exist_ok=True)\n",
        "\n",
        "# Start Aria2c as a daemon process\n",
        "cmd = [\n",
        "    \"aria2c\",\n",
        "    \"--enable-rpc\",\n",
        "    \"--rpc-listen-all=true\",\n",
        "    \"--rpc-allow-origin-all\",\n",
        "    f\"--dir={TEMP_DIR}\",\n",
        "    \"--file-allocation=none\",\n",
        "    \"--max-connection-per-server=16\",\n",
        "    \"--split=16\",\n",
        "    \"--min-split-size=1M\",\n",
        "    \"--seed-time=0\",\n",
        "    \"--daemon=true\"\n",
        "]\n",
        "\n",
        "subprocess.run(\n",
        "    cmd,\n",
        "    stdout=subprocess.DEVNULL,\n",
        "    stderr=subprocess.DEVNULL\n",
        ")\n",
        "\n",
        "print(\"\u2705 Aria2 Background Service Started (DIR: /content/temp_downloads).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step4_md"
      },
      "source": [
        "## 4. \ud83d\udcdd **Create API Backend**\n",
        "Generating the `app.py` file which serves as the brain of CloudLeecher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "step4_code",
        "outputId": "1b65a888-3528-417d-84b4-e69fdfc1ea44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import xmlrpc.client\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "import os\n",
        "import shutil\n",
        "import base64\n",
        "import json\n",
        "import time\n",
        "import threading\n",
        "from datetime import datetime\n",
        "from collections import deque\n",
        "from functools import wraps\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "# Configuration\n",
        "# Aria2 downloads here first (local fast disk)\n",
        "TEMP_DIR = \"/content/temp_downloads\"\n",
        "# Final destination (Google Drive)\n",
        "FINAL_DIR = \"/content/drive/MyDrive/TorrentDownloads\"\n",
        "ARIA2_RPC_URL = \"http://localhost:6800/rpc\"\n",
        "LOG_FILE = \"/content/backend_logs.json\"\n",
        "\n",
        "# Ensure directories exist\n",
        "os.makedirs(TEMP_DIR, exist_ok=True)\n",
        "os.makedirs(FINAL_DIR, exist_ok=True)\n",
        "\n",
        "# In-memory log storage (last 100 entries)\n",
        "logs = deque(maxlen=100)\n",
        "\n",
        "# Connect to Aria2 RPC\n",
        "s = xmlrpc.client.ServerProxy(ARIA2_RPC_URL)\n",
        "\n",
        "def log(level, operation, message, gid=None, extra=None):\n",
        "    \"\"\"Add entry to log with timestamp and details\"\"\"\n",
        "    entry = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"level\": level,  # info, warning, error\n",
        "        \"operation\": operation,\n",
        "        \"message\": message,\n",
        "        \"gid\": gid,\n",
        "        \"extra\": extra\n",
        "    }\n",
        "    logs.append(entry)\n",
        "    \n",
        "    # Also write to file for persistence\n",
        "    try:\n",
        "        with open(LOG_FILE, 'a') as f:\n",
        "            f.write(json.dumps(entry) + '\\n')\n",
        "    except:\n",
        "        pass  # Don't crash on log write failure\n",
        "    \n",
        "    # Print to console for Colab visibility\n",
        "    print(f\"[{level.upper()}] {operation}: {message}\" + (f\" (GID: {gid})\" if gid else \"\"))\n",
        "\n",
        "# --- Authentication Middleware ---\n",
        "def require_api_key(f):\n",
        "    @wraps(f)\n",
        "    def decorated_function(*args, **kwargs):\n",
        "        api_key = os.environ.get('CLOUDLEECHER_API_KEY')\n",
        "        # If no key is set in env, we might be in dev mode or insecure mode, \n",
        "        # but for production hardening we should enforce it if it exists.\n",
        "        # If the notebook didn't set it, we default to open (or we could enforce generating one).\n",
        "        # For now, if the env var exists, we check it.\n",
        "        if api_key:\n",
        "            request_key = request.headers.get('x-api-key')\n",
        "            if not request_key or request_key != api_key:\n",
        "                return jsonify({\"error\": \"Unauthorized: Invalid API Key\"}), 401\n",
        "        return f(*args, **kwargs)\n",
        "    return decorated_function\n",
        "\n",
        "# --- Background Monitor for Move-to-Drive ---\n",
        "class BackgroundMonitor(threading.Thread):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.daemon = True\n",
        "        self.moving_tasks = {} # gid -> task_info\n",
        "        self.saved_tasks = {}  # gid -> task_info\n",
        "        self.lock = threading.Lock()\n",
        "        \n",
        "    def run(self):\n",
        "        log(\"info\", \"monitor\", \"Background monitor started\")\n",
        "        while True:\n",
        "            try:\n",
        "                self.check_completed_downloads()\n",
        "            except Exception as e:\n",
        "                log(\"error\", \"monitor\", f\"Monitor loop error: {str(e)}\")\n",
        "            time.sleep(5)\n",
        "\n",
        "    def check_completed_downloads(self):\n",
        "        try:\n",
        "            # Get stopped tasks to find completed ones\n",
        "            stopped = s.aria2.tellStopped(0, 100, [\"gid\", \"status\", \"files\", \"totalLength\", \"completedLength\", \"errorCode\", \"errorMessage\"])\n",
        "            \n",
        "            for task in stopped:\n",
        "                gid = task['gid']\n",
        "                \n",
        "                # We only care about 'complete' tasks\n",
        "                if task['status'] == 'complete':\n",
        "                    \n",
        "                    # Check if already processing or processed\n",
        "                    with self.lock:\n",
        "                        if gid in self.moving_tasks or gid in self.saved_tasks:\n",
        "                            continue\n",
        "                        \n",
        "                        # Mark as moving\n",
        "                        self.moving_tasks[gid] = {\n",
        "                            \"gid\": gid,\n",
        "                            \"name\": self.get_task_name(task),\n",
        "                            \"status\": \"moving\",\n",
        "                            \"totalLength\": task['totalLength'],\n",
        "                            \"completedLength\": task['completedLength'],\n",
        "                            \"progress\": 100,\n",
        "                            \"speed\": 0\n",
        "                        }\n",
        "                    \n",
        "                    # Start move operation in a separate thread to not block the monitor loop\n",
        "                    threading.Thread(target=self.move_to_drive, args=(gid, task)).start()\n",
        "                    \n",
        "                # We could also auto-clean errors here if we wanted\n",
        "                \n",
        "        except Exception as e:\n",
        "            log(\"error\", \"monitor_check\", f\"Failed to check downloads: {str(e)}\")\n",
        "\n",
        "    def get_task_name(self, task):\n",
        "        if task.get('files') and len(task['files']) > 0:\n",
        "            return os.path.basename(task['files'][0]['path'])\n",
        "        return \"Unknown\"\n",
        "\n",
        "    def move_to_drive(self, gid, task):\n",
        "        log(\"info\", \"move_to_drive\", \"Starting move to Drive\", gid=gid)\n",
        "        \n",
        "        try:\n",
        "            files = task.get('files', [])\n",
        "            if not files:\n",
        "                log(\"warning\", \"move_to_drive\", \"No files found for task\", gid=gid)\n",
        "                self._mark_saved(gid, success=False, error=\"No files found\")\n",
        "                return\n",
        "\n",
        "            # Determine source path (usually the first file's path or directory)\n",
        "            # Aria2 structure: if single file, path is full path. If multi-file, it's inside a dir.\n",
        "            # However, we set --dir=TEMP_DIR. \n",
        "            # If multi-file torrent, aria2 creates a subdir in TEMP_DIR.\n",
        "            # If single-file, it creates the file in TEMP_DIR.\n",
        "            \n",
        "            source_path = files[0]['path']\n",
        "            \n",
        "            # Check if the source path exists\n",
        "            if not os.path.exists(source_path):\n",
        "                 log(\"error\", \"move_to_drive\", f\"Source not found: {source_path}\", gid=gid)\n",
        "                 # Wait a bit, maybe file system lag?\n",
        "                 time.sleep(2)\n",
        "                 if not os.path.exists(source_path):\n",
        "                     self._mark_saved(gid, success=False, error=\"Source file missing\")\n",
        "                     # Remove from aria2 to stop retry loops\n",
        "                     try: s.aria2.removeDownloadResult(gid)\n",
        "                     except: pass\n",
        "                     return\n",
        "\n",
        "            # Determine what to move. \n",
        "            # If it's a multi-file torrent, we want to move the top-level directory.\n",
        "            # If aria2 reports path as \"TEMP_DIR/MyMovie/video.mp4\", and \"TEMP_DIR/MyMovie/subs.srt\"\n",
        "            # We want to move \"TEMP_DIR/MyMovie\".\n",
        "            \n",
        "            # Logic: Get the relative path from TEMP_DIR\n",
        "            rel_path = os.path.relpath(source_path, TEMP_DIR)\n",
        "            top_level_name = rel_path.split(os.sep)[0]\n",
        "            move_source = os.path.join(TEMP_DIR, top_level_name)\n",
        "            move_dest = os.path.join(FINAL_DIR, top_level_name)\n",
        "\n",
        "            log(\"info\", \"move_to_drive\", f\"Moving {move_source} -> {move_dest}\", gid=gid)\n",
        "\n",
        "            # Handle collision\n",
        "            if os.path.exists(move_dest):\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                name, ext = os.path.splitext(top_level_name)\n",
        "                # If it's a directory, ext is empty usually, but splitext works.\n",
        "                if os.path.isdir(move_source):\n",
        "                    new_name = f\"{top_level_name}_{timestamp}\"\n",
        "                else:\n",
        "                    new_name = f\"{name}_{timestamp}{ext}\"\n",
        "                move_dest = os.path.join(FINAL_DIR, new_name)\n",
        "                log(\"warning\", \"move_to_drive\", f\"Destination exists, renaming to {new_name}\", gid=gid)\n",
        "\n",
        "            # Perform Move\n",
        "            shutil.move(move_source, move_dest)\n",
        "            \n",
        "            # Success\n",
        "            log(\"info\", \"move_to_drive\", \"Move completed successfully\", gid=gid)\n",
        "            self._mark_saved(gid, success=True)\n",
        "            \n",
        "            # Clean up Aria2 record\n",
        "            try:\n",
        "                s.aria2.removeDownloadResult(gid)\n",
        "            except Exception as e:\n",
        "                log(\"warning\", \"cleanup\", f\"Failed to remove result from Aria2: {e}\", gid=gid)\n",
        "                \n",
        "        except Exception as e:\n",
        "            log(\"error\", \"move_to_drive\", f\"Move failed: {str(e)}\", gid=gid)\n",
        "            self._mark_saved(gid, success=False, error=str(e))\n",
        "\n",
        "    def _mark_saved(self, gid, success=True, error=None):\n",
        "        with self.lock:\n",
        "            if gid in self.moving_tasks:\n",
        "                task = self.moving_tasks.pop(gid)\n",
        "                task['status'] = 'saved' if success else 'error'\n",
        "                if error:\n",
        "                    task['errorMessage'] = error\n",
        "                self.saved_tasks[gid] = task\n",
        "\n",
        "monitor = BackgroundMonitor()\n",
        "monitor.start()\n",
        "\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health():\n",
        "    return jsonify({\"status\": \"ok\", \"service\": \"CloudLeecher-Backend\"})\n",
        "\n",
        "@app.route('/api/logs', methods=['GET'])\n",
        "@require_api_key\n",
        "def get_logs():\n",
        "    \"\"\"Return recent backend logs for frontend inspection\"\"\"\n",
        "    try:\n",
        "        return jsonify({\"logs\": list(logs)})\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/download/magnet', methods=['POST'])\n",
        "@require_api_key\n",
        "def add_magnet():\n",
        "    data = request.json\n",
        "    magnet_link = data.get('magnet')\n",
        "    if not magnet_link:\n",
        "        log(\"error\", \"add_magnet\", \"Magnet link is required\")\n",
        "        return jsonify({\"error\": \"Magnet link is required\"}), 400\n",
        "    \n",
        "    # BACKEND QUEUE ENFORCEMENT: Only allow one active download\n",
        "    active = s.aria2.tellActive([\"gid\", \"status\"])\n",
        "    waiting = s.aria2.tellWaiting(0, 100, [\"gid\", \"status\"])\n",
        "    \n",
        "    if len(active) > 0 or len(waiting) > 0:\n",
        "        log(\"warning\", \"add_magnet\", f\"Rejected: {len(active)} active, {len(waiting)} waiting tasks already exist\")\n",
        "        return jsonify({\"error\": \"Another download is already in progress. Please wait for it to complete.\"}), 429\n",
        "    \n",
        "    try:\n",
        "        options = {\"dir\": TEMP_DIR}\n",
        "        gid = s.aria2.addUri([magnet_link], options)\n",
        "        log(\"info\", \"add_magnet\", \"Magnet link added successfully\", gid=gid, extra={\"magnet\": magnet_link[:50] + \"...\"})\n",
        "        return jsonify({\"status\": \"success\", \"gid\": gid})\n",
        "    except Exception as e:\n",
        "        log(\"error\", \"add_magnet\", f\"Failed: {str(e)}\", extra={\"magnet\": magnet_link[:50] + \"...\"})\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/download/file', methods=['POST'])\n",
        "@require_api_key\n",
        "def add_torrent_file():\n",
        "    try:\n",
        "        data = request.json\n",
        "        b64_content = data.get('torrent')\n",
        "        if not b64_content:\n",
        "            log(\"error\", \"add_torrent_file\", \"Torrent file content is required\")\n",
        "            return jsonify({\"error\": \"Torrent file content is required\"}), 400\n",
        "\n",
        "        # BACKEND QUEUE ENFORCEMENT: Only allow one active download\n",
        "        active = s.aria2.tellActive([\"gid\", \"status\"])\n",
        "        waiting = s.aria2.tellWaiting(0, 100, [\"gid\", \"status\"])\n",
        "        \n",
        "        if len(active) > 0 or len(waiting) > 0:\n",
        "            log(\"warning\", \"add_torrent_file\", f\"Rejected: {len(active)} active, {len(waiting)} waiting tasks already exist\")\n",
        "            return jsonify({\"error\": \"Another download is already in progress. Please wait for it to complete.\"}), 429\n",
        "\n",
        "        raw_bytes = base64.b64decode(b64_content)\n",
        "        binary_torrent = xmlrpc.client.Binary(raw_bytes)\n",
        "        \n",
        "        log(\"info\", \"add_torrent_file\", f\"Received torrent file ({len(raw_bytes)} bytes), adding to aria2...\")\n",
        "        options = {\"dir\": TEMP_DIR}\n",
        "        gid = s.aria2.addTorrent(binary_torrent, [], options)\n",
        "        log(\"info\", \"add_torrent_file\", \"Torrent file added successfully, downloading metadata...\", gid=gid)\n",
        "        \n",
        "        # Try to get immediate status to log torrent info\n",
        "        try:\n",
        "            status = s.aria2.tellStatus(gid, [\"gid\", \"status\", \"files\", \"bittorrent\"])\n",
        "            torrent_name = status.get('bittorrent', {}).get('info', {}).get('name', 'Unknown')\n",
        "            log(\"info\", \"add_torrent_file\", f\"Torrent name: {torrent_name}\", gid=gid, extra={\"status\": status.get('status')})\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        return jsonify({\"status\": \"success\", \"gid\": gid})\n",
        "    except Exception as e:\n",
        "        log(\"error\", \"add_torrent_file\", f\"Failed: {str(e)}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/status', methods=['GET'])\n",
        "@require_api_key\n",
        "def get_status():\n",
        "    try:\n",
        "        # Use safe keys for non-active tasks to avoid API errors/empty responses\n",
        "        basic_keys = [\"gid\", \"status\", \"totalLength\", \"completedLength\", \"downloadSpeed\", \"uploadSpeed\", \"dir\", \"files\", \"errorMessage\", \"errorCode\", \"followedBy\", \"following\"]\n",
        "        extended_keys = basic_keys + [\"numSeeders\", \"connections\", \"infoHash\", \"bittorrent\"]\n",
        "        \n",
        "        active = s.aria2.tellActive(extended_keys)\n",
        "        waiting = s.aria2.tellWaiting(0, 100, basic_keys)\n",
        "        stopped = s.aria2.tellStopped(0, 100, basic_keys)\n",
        "        \n",
        "        # Merge with local Moving/Saved tasks\n",
        "        # We inject them into the 'stopped' or separate lists?\n",
        "        # The frontend handles lists. Let's return them in 'stopped' or a new list?\n",
        "        # Existing frontend expects {active, waiting, stopped}.\n",
        "        # If we put 'moving' and 'saved' tasks into 'stopped' list, the frontend should handle them if it just iterates.\n",
        "        \n",
        "        local_tasks = []\n",
        "        with monitor.lock:\n",
        "             local_tasks.extend(monitor.moving_tasks.values())\n",
        "             local_tasks.extend(monitor.saved_tasks.values())\n",
        "        \n",
        "        # Prepend local tasks to stopped so they appear\n",
        "        stopped = local_tasks + stopped\n",
        "        \n",
        "        # Track GID transitions for debugging\n",
        "        all_tasks = active + waiting + stopped\n",
        "        all_gids = [t['gid'] for t in all_tasks]\n",
        "        \n",
        "        # Check for GID relationships (followedBy/following)\n",
        "        gid_transitions = []\n",
        "        for task in all_tasks:\n",
        "            if task.get('followedBy'):\n",
        "                # This task created follow-up tasks\n",
        "                for followed_gid in task['followedBy']:\n",
        "                    gid_transitions.append(f\"{task['gid'][:8]} \u2192 {followed_gid[:8]}\")\n",
        "            \n",
        "        if all_gids:\n",
        "            log_msg = f\"Currently tracking {len(all_gids)} tasks\"\n",
        "            if gid_transitions:\n",
        "                log_msg += f\" | Transitions: {', '.join(gid_transitions)}\"\n",
        "            # Reduce log spam\n",
        "            # log(\"info\", \"status_poll\", log_msg, extra={\"gids\": all_gids})\n",
        "        \n",
        "        return jsonify({\n",
        "            \"active\": active,\n",
        "            \"waiting\": waiting,\n",
        "            \"stopped\": stopped\n",
        "        })\n",
        "    except Exception as e:\n",
        "        log(\"error\", \"get_status\", f\"Failed: {str(e)}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/control/pause', methods=['POST'])\n",
        "@require_api_key\n",
        "def pause_download():\n",
        "    try:\n",
        "        gid = request.json.get('gid')\n",
        "        s.aria2.pause(gid)\n",
        "        log(\"info\", \"pause_download\", \"Download paused\", gid=gid)\n",
        "        return jsonify({\"status\": \"paused\", \"gid\": gid})\n",
        "    except Exception as e:\n",
        "        log(\"error\", \"pause_download\", f\"Failed: {str(e)}\", gid=request.json.get('gid'))\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/control/resume', methods=['POST'])\n",
        "@require_api_key\n",
        "def resume_download():\n",
        "    try:\n",
        "        gid = request.json.get('gid')\n",
        "        s.aria2.unpause(gid)\n",
        "        log(\"info\", \"resume_download\", \"Download resumed\", gid=gid)\n",
        "        return jsonify({\"status\": \"resumed\", \"gid\": gid})\n",
        "    except Exception as e:\n",
        "        log(\"error\", \"resume_download\", f\"Failed: {str(e)}\", gid=request.json.get('gid'))\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/control/remove', methods=['POST'])\n",
        "@require_api_key\n",
        "def remove_download():\n",
        "    try:\n",
        "        gid = request.json.get('gid')\n",
        "        \n",
        "        # Check if it's a local task (moving/saved)\n",
        "        with monitor.lock:\n",
        "            if gid in monitor.moving_tasks:\n",
        "                # Can't easily stop a shutil.move, but we can remove it from list so it disappears\n",
        "                del monitor.moving_tasks[gid]\n",
        "                log(\"info\", \"remove_download\", \"Removed moving task from tracking\", gid=gid)\n",
        "                return jsonify({\"status\": \"removed\", \"gid\": gid})\n",
        "            if gid in monitor.saved_tasks:\n",
        "                del monitor.saved_tasks[gid]\n",
        "                log(\"info\", \"remove_download\", \"Removed saved task from history\", gid=gid)\n",
        "                return jsonify({\"status\": \"removed\", \"gid\": gid})\n",
        "\n",
        "        s.aria2.forceRemove(gid)\n",
        "        log(\"info\", \"remove_download\", \"Download removed\", gid=gid)\n",
        "        return jsonify({\"status\": \"removed\", \"gid\": gid})\n",
        "    except xmlrpc.client.Fault as e:\n",
        "        # Check if this is a \"GID not found\" error (common when frontend has stale tasks)\n",
        "        if 'not found' in str(e).lower():\n",
        "            log(\"info\", \"remove_download\", \"GID not found (already removed or from previous session)\", gid=request.json.get('gid'))\n",
        "            # Return success anyway since the goal (task not present) is achieved\n",
        "            return jsonify({\"status\": \"removed\", \"gid\": request.json.get('gid')})\n",
        "        else:\n",
        "            # Log other aria2 faults as errors\n",
        "            log(\"error\", \"remove_download\", f\"Aria2 error: {str(e)}\", gid=request.json.get('gid'))\n",
        "            return jsonify({\"error\": str(e)}), 500\n",
        "    except Exception as e:\n",
        "        log(\"error\", \"remove_download\", f\"Failed: {str(e)}\", gid=request.json.get('gid'))\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/drive/info', methods=['GET'])\n",
        "@require_api_key\n",
        "def drive_info():\n",
        "    try:\n",
        "        # Check drive info on the Final Dir\n",
        "        total, used, free = shutil.disk_usage(FINAL_DIR)\n",
        "        return jsonify({\n",
        "            \"total\": total,\n",
        "            \"used\": used,\n",
        "            \"free\": free\n",
        "        })\n",
        "    except Exception as e:\n",
        "        return jsonify({\"total\": 0, \"used\": 0, \"free\": 0})\n",
        "\n",
        "@app.route('/api/cleanup', methods=['POST'])\n",
        "@require_api_key\n",
        "def cleanup_all():\n",
        "    \"\"\"Nuclear option: Remove ALL tasks from aria2 and start fresh\"\"\"\n",
        "    try:\n",
        "        # Get all tasks\n",
        "        active = s.aria2.tellActive([\"gid\"])\n",
        "        waiting = s.aria2.tellWaiting(0, 9999, [\"gid\"])\n",
        "        stopped = s.aria2.tellStopped(0, 9999, [\"gid\"])\n",
        "        \n",
        "        removed_count = 0\n",
        "        \n",
        "        # Force remove all active and waiting\n",
        "        for task in active + waiting:\n",
        "            try:\n",
        "                s.aria2.forceRemove(task['gid'])\n",
        "                removed_count += 1\n",
        "            except:\n",
        "                pass\n",
        "        \n",
        "        # Purge all stopped\n",
        "        try:\n",
        "            s.aria2.purgeDownloadResult()\n",
        "            removed_count += len(stopped)\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        # Clear local tracking\n",
        "        with monitor.lock:\n",
        "            monitor.moving_tasks.clear()\n",
        "            monitor.saved_tasks.clear()\n",
        "        \n",
        "        log(\"info\", \"cleanup_all\", f\"Cleaned up {removed_count} tasks\")\n",
        "        return jsonify({\"status\": \"success\", \"removed\": removed_count})\n",
        "    except Exception as e:\n",
        "        log(\"error\", \"cleanup_all\", f\"Failed: {str(e)}\")\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "def purge_stalled_downloads():\n",
        "    \"\"\"Automatically remove stalled/failed downloads\"\"\"\n",
        "    try:\n",
        "        stopped = s.aria2.tellStopped(0, 100, [\"gid\", \"status\", \"errorCode\", \"completedLength\", \"totalLength\"])\n",
        "        \n",
        "        purged = 0\n",
        "        for task in stopped:\n",
        "            # Remove completed or errored tasks\n",
        "            # Note: We should be careful not to remove 'complete' tasks before the monitor picks them up!\n",
        "            # The monitor checks every 5s. This runs on startup.\n",
        "            if task['status'] in ['error', 'removed']:\n",
        "                try:\n",
        "                    s.aria2.removeDownloadResult(task['gid'])\n",
        "                    purged += 1\n",
        "                except:\n",
        "                    pass\n",
        "        \n",
        "        if purged > 0:\n",
        "            log(\"info\", \"auto_purge\", f\"Automatically purged {purged} failed tasks\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        pass  # Silent fail for background cleanup\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    log(\"info\", \"startup\", \"CloudLeecher Backend starting...\")\n",
        "    \n",
        "    # Clean up any existing stalled tasks on startup\n",
        "    log(\"info\", \"startup\", \"Cleaning up stalled tasks from previous session...\")\n",
        "    purge_stalled_downloads()\n",
        "    \n",
        "    app.run(port=5000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step5_md"
      },
      "source": [
        "## 5. \ud83c\udf10 **Launch Public Server**\n",
        "Starting the application and generating your public access URL.\n",
        "\n",
        "> **\u26a0\ufe0f Important**: Ensure you have added your Ngrok Authtoken to Colab Secrets with the key `NGROK-AUTHTOKEN`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "step5_code",
        "outputId": "f986933a-8318-4562-c19d-10332aa85446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "\ud83d\udd17 PUBLIC URL: https://vitalistically-falsifiable-donnette.ngrok-free.dev\n",
            "============================================================\n",
            "\n",
            "\u2705 CloudLeecher Backend is Online!\n",
            "\ud83c\udf0d Frontend App: https://cloudleecher.web.app\n",
            "\ud83d\udccb Copy the URL above (PUBLIC URL) and paste it into the CloudLeecher Frontend app.\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "import subprocess\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "import uuid\n",
        "\n",
        "# 1. Authenticate Ngrok\n",
        "try:\n",
        "    AUTH_TOKEN = userdata.get(\"NGROK-AUTHTOKEN\")\n",
        "    ngrok.set_auth_token(AUTH_TOKEN)\n",
        "except Exception as e:\n",
        "    print(\"\u274c Error: Ngrok Auth Token not found! Please add 'NGROK-AUTHTOKEN' to Colab Secrets (Key icon on the left).\")\n",
        "    raise e\n",
        "\n",
        "# 2. Cleanup Old Processes (Port 5000)\n",
        "ngrok.kill()\n",
        "os.system(\"fuser -k 5000/tcp > /dev/null 2>&1\")\n",
        "\n",
        "# 3. Generate Secure API Key\n",
        "api_key = str(uuid.uuid4())\n",
        "os.environ[\"CLOUDLEECHER_API_KEY\"] = api_key\n",
        "\n",
        "# 4. Start Flask App in Background\n",
        "log_file = open(\"flask.log\", \"w\")\n",
        "# Pass the environment with the API Key\n",
        "env = os.environ.copy()\n",
        "subprocess.Popen([sys.executable, \"app.py\"], stdout=log_file, stderr=log_file, env=env)\n",
        "time.sleep(3)  # Allow Flask to initialize\n",
        "\n",
        "# 5. Open Ngrok Tunnel\n",
        "try:\n",
        "    public_url = ngrok.connect(5000).public_url\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"\ud83d\udd17 PUBLIC URL: {public_url}\")\n",
        "    print(f\"\ud83d\udd11 API KEY:    {api_key}\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "    print(\"\u2705 CloudLeecher Backend is Online!\")\n",
        "    print(\"\ud83c\udf0d Frontend App: https://cloudleecher.web.app\")\n",
        "    print(\"\ud83d\udccb Copy the URL and API KEY above and paste them into the CloudLeecher Frontend app.\")\n",
        "\n",
        "    # Keep cell running to keep thread alive\n",
        "    while True:\n",
        "        time.sleep(10)\n",
        "except Exception as e:\n",
        "    print(f\"\u274c Failed to start Ngrok: {e}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}